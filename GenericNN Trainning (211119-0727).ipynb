{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef7659d-2eda-4117-bdde-ad1414380768",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 1,
     "id": "4ef7659d-2eda-4117-bdde-ad1414380768",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#1\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from PIL import Image,ImageChops\n",
    "from torchvision import transforms\n",
    "\n",
    "#from torch_lr_finder import LRFinder\n",
    "from tqdm.notebook import tqdm_notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ad2ba1-abde-436e-8588-77108f23b3a7",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 2,
     "id": "b3ad2ba1-abde-436e-8588-77108f23b3a7",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#2\n",
    "class ConvBnAct(nn.Module):\n",
    "    \"\"\"Layer grouping a convolution, batchnorm, and activation function\"\"\"\n",
    "    def __init__(self, n_in, n_out, kernel_size=3, stride=1, padding=0, groups=1, bias=False, bn=True, act=True):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(n_in, n_out, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=bias)\n",
    "        self.bn   = nn.BatchNorm2d(n_out) if bn else nn.Identity()\n",
    "        self.act  = nn.SiLU() if act else nn.Identity()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class SEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-excitation block\"\"\"\n",
    "    def __init__(self, n_in, r=24):\n",
    "        super().__init__()\n",
    "\n",
    "        N = n_in if (n_in//r == 0) else n_in//r \n",
    "\n",
    "        self.squeeze    = nn.AdaptiveAvgPool2d(1)\n",
    "        self.excitation = nn.Sequential(nn.Conv2d(n_in, N, kernel_size=1),\n",
    "                                        nn.SiLU(),\n",
    "                                        nn.Conv2d(N, n_in, kernel_size=1),\n",
    "                                        nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.squeeze(x)\n",
    "        y = self.excitation(y)\n",
    "        return x * y\n",
    "\n",
    "class DropSample(nn.Module):\n",
    "    \"\"\"Drops each sample in x with probability p during training\"\"\"\n",
    "    def __init__(self, p=0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.p = p\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if (not self.p) or (not self.training): return x\n",
    "        \n",
    "        batch_size = len(x)\n",
    "        random_tensor = torch.cuda.FloatTensor(batch_size, 1, 1, 1).uniform_()\n",
    "        bit_mask = self.p<random_tensor\n",
    "\n",
    "        x = x.div(1-self.p)\n",
    "        x = x * bit_mask\n",
    "        return x\n",
    "\n",
    "class MBConvN(nn.Module):\n",
    "    \"\"\"MBConv with an expansion factor of N, plus squeeze-and-excitation\"\"\"\n",
    "    def __init__(self, n_in, n_out, expansion_factor, kernel_size=3, stride=1, r=24, p=0):\n",
    "        super().__init__()\n",
    "\n",
    "        padding = (kernel_size-1)//2\n",
    "        expanded = expansion_factor*n_in\n",
    "        self.skip_connection = (n_in == n_out) and (stride == 1)\n",
    "\n",
    "        self.expand_pw  = nn.Identity() if (expansion_factor == 1) else ConvBnAct(n_in, expanded, kernel_size=1)\n",
    "        self.depthwise  = ConvBnAct(expanded, expanded, kernel_size=kernel_size, stride=stride, padding=padding, groups=expanded)\n",
    "        self.se         = SEBlock(expanded, r=r)\n",
    "        self.reduce_pw  = ConvBnAct(expanded, n_out, kernel_size=1, act=False)\n",
    "        self.dropsample = DropSample(p)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        x = self.expand_pw(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.se(x)\n",
    "        x = self.reduce_pw(x)\n",
    "\n",
    "        if self.skip_connection:\n",
    "            x = self.dropsample(x)\n",
    "            x = x + residual\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4144bdb-af54-4a0e-bb32-be253574564f",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 3,
     "id": "c4144bdb-af54-4a0e-bb32-be253574564f",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#3\n",
    "p = 0\n",
    "class GenericNN(nn.Module):\n",
    "    \"\"\"Generic EfficientNet that takes in the width and depth scale factors and scales accordingly\"\"\"\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "\n",
    "      self.stem  = ConvBnAct(1, 32, stride=2, padding=1)\n",
    "\n",
    "      self.stages = nn.Sequential( MBConvN(32, 16, 1,3,2,24,0)\n",
    "                                  ,MBConvN(16, 16, 4,3,2,24,0)\n",
    "                                  ,MBConvN(16, 16, 4,3,1,24,0)\n",
    "\n",
    "                                  ,MBConvN(16, 24, 4,3,2,24,p*0.05)\n",
    "                                  ,MBConvN(24, 24, 4,3,1,24,p*0.05)\n",
    "                                  \n",
    "                                  ,MBConvN(24, 40, 4,3,2,24,p*0.015)\n",
    "                                  ,MBConvN(40, 40, 4,3,1,24,p*0.015)\n",
    "\n",
    "                                  ,MBConvN(40, 80, 4,3,1,24,p*0.025)\n",
    "                                  ,MBConvN(80, 80, 4,3,1,24,p*0.025)\n",
    "\n",
    "                                  ,MBConvN(80, 112, 4,3,2,24,p*0.035)\n",
    "                                  ,MBConvN(112,112, 4,3,1,24,p*0.035)\n",
    "\n",
    "                                  ,MBConvN(112, 192, 4,3,2,24,p*0.045)\n",
    "                                  ,MBConvN(192, 192, 4,3,1,24,p*0.045)\n",
    "                                )\n",
    "\n",
    "      self.head = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n",
    "                               nn.Flatten(),\n",
    "                               nn.Linear(192,2)\n",
    "                               )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "      x = self.stem(x)\n",
    "      x = self.stages(x)\n",
    "      x = self.head(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b56861-1f02-46f1-9545-e815105ec4cd",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 4,
     "id": "a6b56861-1f02-46f1-9545-e815105ec4cd",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#4\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class CFG:\n",
    "    Check_Point_Rate = 1\n",
    "    img_size         = 800\n",
    "    batch_size       = 20#10#6#40 #para VGG\n",
    "    epoch            = 50\n",
    "    address          = \"./110mm 5.10.2021\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c79081-bcb9-4cd7-9e59-9bbcc257ebc6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 16,
     "id": "38c79081-bcb9-4cd7-9e59-9bbcc257ebc6",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#5\n",
    "train_tfms = transforms.Compose([\n",
    "                                  transforms.Grayscale()\n",
    "                                 ,transforms.ToTensor()\n",
    "                                 \n",
    "                                 ,transforms.Lambda(lambda x: x.masked_fill_((x > 0.5),0))\n",
    "                                 ,transforms.Lambda(lambda x: transforms.functional.autocontrast(x))  \n",
    "                                 #,transforms.Lambda(lambda x: ImageChops.invert(x))                                 \n",
    "                                 #,transforms.RandomAffine(degrees=(-180,180),fill=255,translate=(0.01,0.01))#,scale=(.99,1.01))\n",
    "                                 ,transforms.Resize((CFG.img_size, CFG.img_size))\n",
    "                                 ,transforms.RandomHorizontalFlip(p=0.5)\n",
    "                                 ,transforms.RandomVerticalFlip(p=0.5)\n",
    "                                 #,transforms.Lambda(lambda x: x.masked_fill_((x < 0.5),0))    \n",
    "                                 #,transforms.Lambda(lambda x: sobel(x))\n",
    "                                 #,transforms.Lambda(lambda x: x.masked_fill_((x > 0.5),1))\n",
    "                                 #,transforms.Lambda(lambda x: transforms.functional.autocontrast(x)) \n",
    "                                 #,transforms.Normalize((0.226), (0.694))\n",
    "                                 ])\n",
    "\n",
    "valid_tfms = transforms.Compose([\n",
    "                                  transforms.Grayscale()\n",
    "                                 ,transforms.ToTensor()\n",
    "    \n",
    "                                 #,transforms.RandomAffine(degrees=(-180,180),fill=255,translate=(0.01,0.01))#,scale=(.99,1.01))\n",
    "                                 ,transforms.Lambda(lambda x: x.masked_fill_((x > 0.5),0))\n",
    "                                 ,transforms.Lambda(lambda x: transforms.functional.autocontrast(x))                             \n",
    "                                 ,transforms.Resize((CFG.img_size, CFG.img_size))\n",
    "                                 ])\n",
    "\n",
    "trainDataset = torchvision.datasets.ImageFolder(CFG.address + \"/Train/\",transform=train_tfms)\n",
    "validDataset = torchvision.datasets.ImageFolder(CFG.address + \"/Test/\",transform=valid_tfms)\n",
    "testDataset  = torchvision.datasets.ImageFolder(\"./110mm 1.11.2021\" + \"/Test/\",transform=valid_tfms)\n",
    "\n",
    "print(len(trainDataset), len(validDataset), len(testDataset))\n",
    "\n",
    "trainDataLoader = DataLoader(dataset=trainDataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "validDataLoader = DataLoader(dataset=validDataset, batch_size=CFG.batch_size)\n",
    "testDataLoader  = DataLoader(dataset=testDataset , batch_size=CFG.batch_size)\n",
    "\n",
    "print(len(trainDataLoader), len(validDataLoader), len(testDataLoader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028d819-050e-4189-b3ff-9a5fecb051d6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 17,
     "id": "d028d819-050e-4189-b3ff-9a5fecb051d6",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#6\n",
    "tensorToImage = torchvision.transforms.ToPILImage()\n",
    "imageToTensor = torchvision.transforms.ToTensor()\n",
    "img_train, A = trainDataset[33]\n",
    "img_valid, B = validDataset[50]\n",
    "img_test , C = testDataset[5]\n",
    "tensorToImage(img_train).show(),tensorToImage(img_valid).show(),tensorToImage(img_test).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c093f0b-0019-48c9-971d-0c1c327fdff6",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 7,
     "id": "2c093f0b-0019-48c9-971d-0c1c327fdff6",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#7\n",
    "def Test(DataLoader):\n",
    "    model.eval() \n",
    "    total     = 0\n",
    "    loss      = 0\n",
    "    accuracy  = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        t =  tqdm_notebook(DataLoader)\n",
    "        for (inputs, labels) in t:\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "                         \n",
    "            logps      = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "\n",
    "            loss      += batch_loss.item()\n",
    "            accuracy  += (torch.argmax(logps,1) == labels).sum().item()\n",
    "            total     += labels.size()[0]\n",
    "\n",
    "            t.set_postfix_str(\"Test: %f\" % batch_loss)\n",
    "           \n",
    "    return  accuracy/total, loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ce5bc-8050-4a05-923d-5bea3a9b344d",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 8,
     "id": "617ce5bc-8050-4a05-923d-5bea3a9b344d",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#8\n",
    "def Train(DataLoader, Optimizer):    \n",
    "        model.train()        \n",
    "        loss  = 0\n",
    "        total = 0\n",
    "        \n",
    "        t =  tqdm_notebook(DataLoader)\n",
    "        for (inputs, labels) in t:\n",
    "            inputs, labels = inputs.to(device),labels.to(device)\n",
    "\n",
    "            logps      = model.forward(inputs)\n",
    "            batch_loss = criterion(logps, labels)\n",
    "           \n",
    "            Optimizer.zero_grad();\n",
    "            batch_loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "            Optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            loss  += batch_loss.item()\n",
    "            total += labels.size()[0]\n",
    "            \n",
    "            t.set_postfix_str(\"Train: %f\" % batch_loss)\n",
    "        \n",
    "        return (loss/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5404c43-1840-4760-a441-b2addf267edc",
   "metadata": {
    "gradient": {
     "editing": false,
     "execution_count": 9,
     "id": "a5404c43-1840-4760-a441-b2addf267edc",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#9\n",
    "def Fit():\n",
    "      valid_min_loss =  general_loss#float('inf')\n",
    "      print(\"Initial loss: \",valid_min_loss)\n",
    "      for idx in range(1,CFG.epoch):\n",
    "            print(\"Epoch: {}, Learning Rate: {}\".format(idx,scheduler.get_last_lr())) \n",
    "            Train(trainDataLoader, optimizer)\n",
    "                        \n",
    "            if (idx % CFG.Check_Point_Rate == 0):\n",
    "                acc, loss = Test(trainDataLoader)\n",
    "                accT, lossT = Test(validDataLoader)\n",
    "                print(\"TRAIN ACURACCY: {:.6f}, TRAIN LOSS: {:.6f}\".format(acc, loss))\n",
    "                print(\"TEST ACURACCY : {:.6f}, TEST LOSS : {:.6f}\".format(accT, lossT))\n",
    "                    \n",
    "                if lossT <= valid_min_loss :\n",
    "                    print(\"Valid_loss decreased {} ----------> {}\".format(valid_min_loss,lossT))\n",
    "                    torch.save({\n",
    "                            'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict(),\n",
    "                            'loss': lossT,\n",
    "                            'acc':accT\n",
    "                            }, \"./best_model.pth\")\n",
    "                    \n",
    "                    valid_min_loss = lossT \n",
    "\n",
    "      checkpoint = torch.load(\"./best_model.pth\")\n",
    "      model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "      print(\"BEST: TEST ACURACCY: {:.6f}, TEST LOSS: {:.6f}\".format(checkpoint['acc'],checkpoint['loss']))\n",
    "      torch.save({\n",
    "          'model_state_dict': model.state_dict(),\n",
    "          'optimizer_state_dict': optimizer.state_dict(),\n",
    "          'loss': checkpoint['loss'],\n",
    "          'acc':checkpoint['acc']\n",
    "      }, \"./best_model \" + str(checkpoint['acc']) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17f1058-abc9-421f-b74c-2beb8f5ba0ab",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "c17f1058-abc9-421f-b74c-2beb8f5ba0ab",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#10\n",
    "#Entrenando NN desde Cero\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = GenericNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1E-4, weight_decay=0.08)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1E-5, max_lr=1E-4, cycle_momentum=False)\n",
    "\n",
    "CFG.Check_Point_Rate = 1\n",
    "CFG.epoch = 100\n",
    "\n",
    "general_loss = float(\"inf\")\n",
    "Fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4af27-7880-40ba-b9d2-9d6d25679ae2",
   "metadata": {
    "gradient": {
     "id": "9df4af27-7880-40ba-b9d2-9d6d25679ae2",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#continuar entrenamiento con modelo que YA esta cargado en memoria.\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1E-5, weight_decay=0.03)\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1E-6, max_lr=4E-5, cycle_momentum=False)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=1)\n",
    "CFG.Check_Point_Rate = 1\n",
    "CFG.epoch = 1\n",
    "\n",
    "general_loss = 0.04\n",
    "Fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96e6223-2a75-4aa0-869a-d56a795159a5",
   "metadata": {
    "gradient": {
     "id": "f96e6223-2a75-4aa0-869a-d56a795159a5",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "#Cargando desde archivo para continuar entrenamiento.\n",
    "model = GenericNN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1E-5, weight_decay=0.0)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint = torch.load(\"./best_model.pth\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "for g in optimizer.param_groups:\n",
    "    print( g['lr'])\n",
    "    print(g['weight_decay'])\n",
    "    g['weight_decay'] = 0.0\n",
    "    g['lr'] = 1e-04\n",
    "    general_loss =checkpoint['loss']\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=1E-6, max_lr=4E-5, cycle_momentum=False)\n",
    "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=1)\n",
    "CFG.Check_Point_Rate = 1\n",
    "CFG.epoch = 100\n",
    "\n",
    "Fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c67f79-56cf-45c4-b42c-aefbe6df954a",
   "metadata": {
    "gradient": {
     "editing": false,
     "id": "41c67f79-56cf-45c4-b42c-aefbe6df954a",
     "kernelId": ""
    }
   },
   "outputs": [],
   "source": [
    "!pip install torchsummary\n",
    "from torchsummary import summary\n",
    "\n",
    "image_size = 400\n",
    "\n",
    "summary(model, (1, image_size, image_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
